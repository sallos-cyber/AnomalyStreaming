{
  "paragraphs": [
    {
      "text": "%spark.conf \nSPARK_HOME /home/sscd/Programme/spark/spark-3.1.1-bin-hadoop3.2\n",
      "user": "anonymous",
      "dateUpdated": "2022-04-08 13:30:10.031",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/text",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1644597367854_142126755",
      "id": "paragraph_1644597367854_142126755",
      "dateCreated": "2022-02-11 17:36:07.855",
      "dateStarted": "2022-04-08 13:30:10.142",
      "dateFinished": "2022-04-08 13:30:10.256",
      "status": "FINISHED"
    },
    {
      "text": "%pyspark\nprint(spark)",
      "user": "anonymous",
      "dateUpdated": "2022-04-08 13:31:18.597",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u003cpyspark.sql.session.SparkSession object at 0x7f2227a3e0d0\u003e\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1649059786595_1432023931",
      "id": "paragraph_1649059786595_1432023931",
      "dateCreated": "2022-04-04 10:09:46.747",
      "dateStarted": "2022-04-08 13:31:18.620",
      "dateFinished": "2022-04-08 13:31:59.670",
      "status": "FINISHED"
    },
    {
      "title": "Read in csv, slice into portions of 1,2 or 3 rows and create new csv from that. Write this file to output target. This is to simulate streaming.",
      "text": "%spark.ipyspark\nimport pandas as pd\nimport random\nimport time\n\ninput_file \u003d \"file:///home/sscd/Code/src\"\noutput_file \u003d\u0027/home/sscd/Programme/zeppelin-0.10.0-bin-netinst/bin/tmp/infostealer_flows_processed.csv\u0027\nportion_size\u003d4\n\ndata \u003d pd.read_csv(input_file)\n#enforce certain column ordering:\n\ndf_data \u003d data[[\u0027Datefirstseen\u0027, \u0027SrcIPAddr\u0027, \u0027DstIPAddr\u0027, \u0027Datefirstseenunix\u0027, \u0027Duration\u0027,\u0027Proto\u0027, \u0027SrcPt\u0027, \u0027DstPt\u0027,\u0027Packets\u0027,\u0027Bytes\u0027]]\n\nnr_rows \u003d data.shape[0]\nstart_idx\u003d0\nend_idx\u003drandom.choice(range(1,portion_size))\n\n",
      "user": "anonymous",
      "dateUpdated": "2022-04-08 21:17:44.227",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "ERROR:root:Internal Python error in the inspect module.\nBelow is the traceback from this internal error.\n\n\nKeyboardInterrupt\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1645187757864_953935774",
      "id": "paragraph_1645187757864_953935774",
      "dateCreated": "2022-02-18 13:35:57.864",
      "dateStarted": "2022-04-08 21:17:44.626",
      "dateFinished": "2022-04-08 21:17:48.882",
      "status": "ABORT"
    },
    {
      "text": "%spark.ipyspark\n#for debugging only create a few files\nprint(nr_rows)\n#nr_rows \u003d 30",
      "user": "anonymous",
      "dateUpdated": "2022-04-04 10:14:41.808",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1645445523646_103850297",
      "id": "paragraph_1645445523646_103850297",
      "dateCreated": "2022-02-21 13:12:03.646",
      "dateStarted": "2022-04-04 10:14:41.844",
      "dateFinished": "2022-04-04 10:14:42.204",
      "status": "FINISHED"
    },
    {
      "text": "%spark.ipyspark\nwhile end_idx \u003c nr_rows:\n    data_subset \u003d data.iloc[start_idx:end_idx]\n    print(data_subset.to_string())\n    file_name_output\u003doutput_file+str(start_idx)+\u0027_\u0027+str(end_idx-1)+\u0027.csv\u0027\n    print(file_name_output)\n    data_subset.to_csv(file_name_output, header\u003dFalse)\n    start_idx\u003dend_idx\n    end_idx \u003d end_idx + random.choice(range(1,portion_size))\n    #time.sleep(5)\n",
      "user": "anonymous",
      "dateUpdated": "2022-02-28 12:13:52.952",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1645445113048_1166752248",
      "id": "paragraph_1645445113048_1166752248",
      "dateCreated": "2022-02-21 13:05:13.048",
      "dateStarted": "2022-02-28 12:13:52.989",
      "dateFinished": "2022-02-28 12:14:01.111",
      "status": "ERROR"
    },
    {
      "text": "%sh\nls -a\n",
      "user": "anonymous",
      "dateUpdated": "2022-02-15 13:14:53.280",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1644598666326_2037887308",
      "id": "paragraph_1644598666326_2037887308",
      "dateCreated": "2022-02-11 17:57:46.326",
      "dateStarted": "2022-02-15 13:14:53.323",
      "dateFinished": "2022-02-15 13:15:01.029",
      "status": "FINISHED"
    },
    {
      "text": "%spark.pyspark\nspark\n",
      "user": "anonymous",
      "dateUpdated": "2022-03-07 20:09:18.390",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1644835469779_350180554",
      "id": "paragraph_1644835469779_350180554",
      "dateCreated": "2022-02-14 11:44:29.782",
      "dateStarted": "2022-03-07 20:09:18.440",
      "dateFinished": "2022-03-07 20:10:39.720",
      "status": "FINISHED"
    },
    {
      "title": "File streaming with filter",
      "text": "%spark.ipyspark\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import TimestampType, StringType, StructType, StructField, IntegerType, LongType\nfrom pyspark.sql.functions import col\n\n# Explicitly set schema\nschema \u003d StructType([ \n                      StructField(\"ctr\", IntegerType(), True),\n                      StructField(\"Datefirstseen\", TimestampType(), True),\n                      StructField(\"SrcIPAddr\", StringType(), True),\n                      StructField(\"DstIPAddr\", StringType(), True),\n                      StructField(\"Datefirstseenunix\", IntegerType(), True),\n                      StructField(\"Duration\", IntegerType(), True),\n                      StructField(\"Proto\", StringType(), True),\n                      StructField(\"SrcPt\", IntegerType(), True),\n                      StructField(\"DstPt\", IntegerType(), True),\n                      StructField(\"Packets\", IntegerType(), True),\n                      StructField(\"Bytes\", IntegerType(), True),\n                      ])\n\n# all files in this directory will be read in one at a time, simulating streaming\ninputFolder \u003d \u0027file:///home/sscd/Programme/zeppelin-0.10.0-bin-netinst/bin/tmp/\u0027\n\nflows_streaming \u003d (\n  spark\n    .readStream\n    .schema(schema)\n    .option(\"maxFilesPerTrigger\", 1)\n    .csv(inputFolder)\n)\n\n# filter input for ip\nwindowedCounts \u003d flows_streaming.where(flows_streaming.SrcIPAddr\u003d\u003d\"192.168.56.12\")\n\n# write the filtered result to file \nquery\u003dwindowedCounts.writeStream.format(\"csv\") \\\n    .outputMode(\"append\")\\\n    .option(\"checkpointLocation\",\"file:///home/sscd/Programme/zeppelin-0.10.0-bin-netinst/bin/checkpoint_zep/\")\\\n    .option(\"path\", \"file:///home/sscd/Programme/zeppelin-0.10.0-bin-netinst/bin/csv/\")\\\n    .start()\n\nquery.awaitTermination(timeout\u003d60)\n\n",
      "user": "anonymous",
      "dateUpdated": "2022-04-08 13:33:17.009",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "False"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1644837782325_709893896",
      "id": "paragraph_1644837782325_709893896",
      "dateCreated": "2022-02-14 12:23:02.325",
      "dateStarted": "2022-04-08 13:33:17.018",
      "dateFinished": "2022-04-08 13:34:29.446",
      "status": "FINISHED"
    },
    {
      "text": "%spark.ipyspark\ndef array_to_string(my_list):\n    return \u0027[\u0027 + \u0027,\u0027.join([str(elem) for elem in my_list]) + \u0027]\u0027\n\n",
      "user": "anonymous",
      "dateUpdated": "2022-03-07 19:56:13.245",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1645788633183_1968588826",
      "id": "paragraph_1645788633183_1968588826",
      "dateCreated": "2022-02-25 12:30:33.190",
      "dateStarted": "2022-03-07 19:56:13.268",
      "dateFinished": "2022-03-07 19:56:13.284",
      "status": "ERROR"
    },
    {
      "title": "File streaming with aggregation",
      "text": "%spark.ipyspark\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import TimestampType, StringType, StructType, StructField, IntegerType, LongType\nfrom pyspark.sql.functions import col\n\n# Explicitly set schema\nschema \u003d StructType([ \n                      StructField(\"ctr\", IntegerType(), True),\n                      StructField(\"Datefirstseen\", TimestampType(), True),\n                      StructField(\"SrcIPAddr\", StringType(), True),\n                      StructField(\"DstIPAddr\", StringType(), True),\n                      StructField(\"Datefirstseenunix\", IntegerType(), True),\n                      StructField(\"Duration\", IntegerType(), True),\n                      StructField(\"Proto\", StringType(), True),\n                      StructField(\"SrcPt\", IntegerType(), True),\n                      StructField(\"DstPt\", IntegerType(), True),\n                      StructField(\"Packets\", IntegerType(), True),\n                      StructField(\"Bytes\", IntegerType(), True),\n                      ])\n\ninputPath \u003d \u0027file:///home/sscd/Programme/zeppelin-0.10.0-bin-netinst/bin/tmp/\u0027\n\n\nflows_streaming \u003d (\n  spark\n    .readStream\n    .schema(schema)\n    .option(\"maxFilesPerTrigger\", 1)\n    .csv(inputPath)\n)\n\n#flows_streaming.printSchema()\n# Group the data by window and word and compute the count of each group\n#windowedCounts \u003d flows_streaming \\\n#    .withWatermark(\"Datefirstseen\", \"10 minutes\") \\\n#    .groupBy(window(\"Datefirstseen\", \"1 minutes\")).count()\n\n\n#windowedCounts \u003d flows_streaming.withWatermark(\"Datefirstseen\", \"10 minutes\").groupBy(window(\"Datefirstseen\", \"5 minutes\")).count()\n#print(windowedCounts.printSchema())\n\n\n#array_to_string_udf \u003d udf(array_to_string,StringType())\n\n#windowedCounts \u003d windowedCounts.withColumn(\u0027windowstringified\u0027,array_to_string_udf(windowedCounts[\"window\"]))\n#windowedCounts \u003dwindowedCounts.drop(\u0027window\u0027)\n#windowedCounts.printSchema()\n#    .groupBy(\n#        window(flows_streaming.Datefirstseen, \"10 minutes\"),\n#        flows_streaming.Datefirstseen) \\\n#    .count()\n\navgSignalDF \u003d flows_streaming.withWatermark(\"Datefirstseen\", \"1 seconds\").groupBy(window(\"Datefirstseen\",\"1 seconds\")).count()\n\n    \nprint(\u0027is this widowedCounts streaming?\u0027)\nprint(avgSignalDF.isStreaming)\nprint(avgSignalDF.printSchema())\n#avgSignalDF \u003d avgSignalDF.drop(\u0027window\u0027)\nprint(avgSignalDF.printSchema())\n\nprint(avgSignalDF.printSchema())\nprint(\u0027is this widowedCounts streaming?\u0027)\nprint(avgSignalDF.isStreaming)\n\n\nquery\u003davgSignalDF.writeStream.format(\"csv\") \\\n    .outputMode(\"append\")\\\n    .option(\"checkpointLocation\",\"file:///home/sscd/Programme/zeppelin-0.10.0-bin-netinst/bin/checkpoint_zep/\")\\\n    .option(\"path\", \"file:///home/sscd/Programme/zeppelin-0.10.0-bin-netinst/bin/csv/\")\\\n    .start()\n\nquery.awaitTermination(timeout\u003d60)\n\n",
      "user": "anonymous",
      "dateUpdated": "2022-04-04 11:09:34.580",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true,
        "lineNumbers": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1645614935758_514131887",
      "id": "paragraph_1645614935758_514131887",
      "dateCreated": "2022-02-23 12:15:35.758",
      "dateStarted": "2022-04-04 11:09:34.607",
      "dateFinished": "2022-04-04 11:09:40.460",
      "status": "ERROR"
    },
    {
      "text": "%spark.ipyspark\nquery.stop()\n",
      "user": "anonymous",
      "dateUpdated": "2022-04-04 11:09:08.895",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1645192227097_1164115353",
      "id": "paragraph_1645192227097_1164115353",
      "dateCreated": "2022-02-18 14:50:27.097",
      "dateStarted": "2022-04-04 11:09:08.927",
      "dateFinished": "2022-04-04 11:09:17.497",
      "status": "FINISHED"
    },
    {
      "title": "Cleanup",
      "text": "%sh\n#cleanup \ncd csv\nrm part*.csv\nrm .part-*\nrm -rf _spark_metadata\nls -all\ncd ../checkpoint_zep\nls\nrm -rf commits metdata offsets sources\nrm metadata\nls -all",
      "user": "anonymous",
      "dateUpdated": "2022-04-04 15:48:43.276",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1645191962803_2072503280",
      "id": "paragraph_1645191962803_2072503280",
      "dateCreated": "2022-02-18 14:46:02.803",
      "dateStarted": "2022-04-04 15:48:43.323",
      "dateFinished": "2022-04-04 15:48:43.514",
      "status": "FINISHED"
    },
    {
      "title": "Basic file streaming",
      "text": "%spark.ipyspark\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import TimestampType, StringType, StructType, StructField, IntegerType, LongType\n\n# Explicitly set schema\nschema \u003d StructType([ \n                      StructField(\"ctr\", IntegerType(), True),\n                      StructField(\"Datefirstseen\", TimestampType(), True),\n                      StructField(\"SrcIPAddr\", StringType(), True),\n                      StructField(\"DstIPAddr\", StringType(), True),\n                      StructField(\"Datefirstseenunix\", IntegerType(), True),\n                      StructField(\"Duration\", IntegerType(), True),\n                      StructField(\"Proto\", StringType(), True),\n                      StructField(\"SrcPt\", IntegerType(), True),\n                      StructField(\"DstPt\", IntegerType(), True),\n                      StructField(\"Packets\", IntegerType(), True),\n                      StructField(\"Bytes\", IntegerType(), True),\n                      ])\n\ninputPath \u003d \u0027file:///home/sscd/Programme/zeppelin-0.10.0-bin-netinst/bin/tmp/\u0027\nstreamingDF \u003d (\n  spark\n    .readStream\n    .schema(schema)\n    .option(\"maxFilesPerTrigger\", 1)\n    .csv(inputPath)\n)\n\n\nquery\u003dstreamingDF.writeStream.format(\"csv\") \\\n    .outputMode(\"append\")\\\n    .option(\"checkpointLocation\",\"file:///home/sscd/Programme/zeppelin-0.10.0-bin-netinst/bin/checkpoint_zep/\")\\\n    .option(\"path\", \"file:///home/sscd/Programme/zeppelin-0.10.0-bin-netinst/bin/csv/\")\\\n    .start()\n\n\n\n\nquery.awaitTermination(timeout\u003d60)\n\n",
      "user": "anonymous",
      "dateUpdated": "2022-02-21 12:47:29.329",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1645195625333_1990737154",
      "id": "paragraph_1645195625333_1990737154",
      "dateCreated": "2022-02-18 15:47:05.333",
      "status": "READY"
    },
    {
      "text": "\n#windowedCounts \u003d words.groupBy(\n#    window(words.timestamp, \u002710 seconds\u0027, \u00271 seconds\u0027),\n#    words.word\n#).count().orderBy(\u0027window\u0027)\n\n#print(windowedCounts)\n#query \u003d wordCounts \\\n#    .writeStream \\\n#    .outputMode(\"complete\") \\\n#    .format(\"console\") \\\n#    .start()\n\n#query \u003d wordCounts \\\n#    .writeStream \\\n#    .outputMode(\"complete\") \\\n#    .format(\"memory\") \\\n#    .queryName(\u0027lalala\u0027) \\\n#    .start()\n\n\n#windowedCounts.writeStream.format(\"csv\").outputMode(\"append\").option(\"checkpointLocation\",\"/home/sscd/tmp\").option(\"path\", \"file:///home/sscd/tmp/bla.csv\").start()\n#option(\"checkpointLocation\", \"/tmp/vaquarkhan/checkpoint\"). \n\n#query \u003d (\n#  streaming_ip_src_counts_df\n#    .writeStream\n#    .format(\"memory\")\n#    .queryName(\"counts\")\n#    .outputMode(\"complete\")\n#    .start()\n#)\n\n#words \u003d streamingDF.select(\n#   explode(\n#       split(streamingDF.value, \" \")\n#   ).alias(\"word\")\n#)\n\n# Generate running word count\n#wordCounts \u003d words.groupBy(\"word\").count()\n\n\n#windowedCounts \u003d words.groupBy(\n#    window(words.Datefirstseen, \"10 minutes\", \"5 minutes\"),\n#    words.word\n#).count()\n\n\n#wordCounts.writeStream.format(\"csv\").outputMode(\"append\").option(\"checkpointLocation\",\"/home/sscd/tmp\").option(\"path\", \"file:///home/sscd/tmp/bla.csv\").start()\n#windowedCounts.writeStream.format(\"csv\").outputMode(\"append\").option(\"checkpointLocation\",\"/home/sscd/tmp\").option(\"path\", \"file:///home/sscd/tmp/bla.csv\").start()\n\n\n\n#query \u003d wordCounts \\\n#    .writeStream \\\n#    .outputMode(\"complete\") \\\n#    .format(\"memory\") \\\n#    .queryName(\u0027a_query_name\u0027) \\\n#    .start()\n",
      "user": "anonymous",
      "dateUpdated": "2022-02-18 14:50:25.055",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1644843434348_2076921749",
      "id": "paragraph_1644843434348_2076921749",
      "dateCreated": "2022-02-14 13:57:14.349",
      "dateStarted": "2022-02-18 14:49:12.060",
      "dateFinished": "2022-02-18 14:49:12.437",
      "status": "FINISHED"
    },
    {
      "text": "%pyspark\n# read from tcp socket\n#lines \u003d spark.readStream \\\n#    .format(\u0027socket\u0027) \\\n#    .option(\u0027host\u0027, \u0027localhost\u0027) \\\n#    .option(\u0027port\u0027, 9999) \\\n#    .option(\u0027includeTimestamp\u0027, \u0027true\u0027) \\\n#    .load()\n\n# read from file\n#lines \u003dspark.readStream \\\n#    .schema(schema) \\\n#    .format(\u0027csv\u0027) \\\n#    .option(\u0027path\u0027, \u0027file:///home/sscd/Programme/zeppelin-0.10.0-bin-netinst/bin/tmp/\u0027) \\\n#    .load()\n\ndisplay(streamingDF)\nprint(\u0027\\n\u0027)\nprint(streamingDF.isStreaming)\n\n#streaming_ip_src_counts_df \u003d (\n#  streamingDF\n#    .groupBy(\n#      streamingDF.SrcIPAddr\n#    )\n#    .count()\n#)",
      "user": "anonymous",
      "dateUpdated": "2022-02-18 12:14:36.176",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1645182791296_1760496068",
      "id": "paragraph_1645182791296_1760496068",
      "dateCreated": "2022-02-18 12:13:11.296",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\nspark.table(\"some_name\").show()",
      "user": "anonymous",
      "dateUpdated": "2022-02-14 12:27:42.359",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1644838058381_202749652",
      "id": "paragraph_1644838058381_202749652",
      "dateCreated": "2022-02-14 12:27:38.381",
      "dateStarted": "2022-02-14 12:27:42.373",
      "dateFinished": "2022-02-14 12:27:43.901",
      "status": "ERROR"
    },
    {
      "text": "%spark.ipyspark\n\nfrom pyspark.sql.functions import explode\nfrom pyspark.sql.functions import split\nfrom pyspark.streaming import StreamingContext\nfrom pyspark.sql import SparkSession\nimport time\nspark\nsc \u003d spark._sc\ncontent \u003d sc.textFile(\"file:///tack.csv\")\nprint(content)\n\ndata_raw_df \u003dspark.read.csv(\u0027file:///home/sscd/Programme/zeppelin-0.10.0-bin-netinst/bin/tack.csv\u0027,header\u003dTrue)\ndata_raw_df.show()\n#spark \u003d SparkSession.builder \\\n#        .appName(\u0027fuckingStreaming\u0027) \\\n#        .getOrCreate()\n\n#\n\n\n\nlines \u003dspark.readStream \\\n    .format(\u0027text\u0027) \\\n    .option(\u0027path\u0027, \u0027file:///home/sscd/Programme/zeppelin-0.10.0-bin-netinst/bin/tmp/\u0027) \\\n    .load()\n\n\nwords \u003d lines.select(\n        explode(\n            split(lines.value, \u0027 \u0027)\n        ).alias(\u0027word\u0027)\n)\nwordCounts \u003d words.groupBy(\u0027word\u0027).count()\n\nquery \u003d wordCounts.writeStream.format(\"memory\").outputMode(\"complete\").queryName(\"test\").start()\n\n#query \u003d wordCounts.writeStream \\\n#   .outputMode(\"complete\") \\\n#    .format(\"memory\") \\\n#    .queryName(\u0027some_name\u0027) \\\n#    .start()",
      "user": "anonymous",
      "dateUpdated": "2022-02-14 12:43:15.164",
      "progress": 100,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 671.5,
              "optionOpen": false
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://10.0.2.15:4040/jobs/job?id\u003d19"
            },
            {
              "jobUrl": "http://10.0.2.15:4040/jobs/job?id\u003d20"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1644232765793_123617773",
      "id": "paragraph_1644232765793_123617773",
      "dateCreated": "2022-02-07 12:19:25.793",
      "dateStarted": "2022-02-14 12:43:15.168",
      "dateFinished": "2022-02-14 12:43:17.636",
      "status": "ERROR"
    },
    {
      "text": "%pyspark\n\nspark.table(\"some_name\").show()\n",
      "user": "anonymous",
      "dateUpdated": "2022-02-11 18:02:25.785",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1644597596313_906959217",
      "id": "paragraph_1644597596313_906959217",
      "dateCreated": "2022-02-11 17:39:56.313",
      "dateStarted": "2022-02-11 18:02:25.809",
      "dateFinished": "2022-02-11 18:03:52.981",
      "status": "ERROR"
    },
    {
      "text": "%spark.pyspark\nquery \u003d (windowedCounts\n  .writeStream\n  .outputMode(\"complete\")\n  .format(\"memory\")\n  .queryName(\"some_name\")\n  .start())\n",
      "user": "anonymous",
      "dateUpdated": "2022-02-11 17:37:40.572",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1644597453361_1295447311",
      "id": "paragraph_1644597453361_1295447311",
      "dateCreated": "2022-02-11 17:37:33.361",
      "status": "READY"
    },
    {
      "text": "%spark.ipyspark\nspark.table(\"some_name\").show()",
      "user": "anonymous",
      "dateUpdated": "2022-02-11 13:46:52.594",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1644583594615_1634735367",
      "id": "paragraph_1644583594615_1634735367",
      "dateCreated": "2022-02-11 13:46:34.616",
      "status": "READY"
    },
    {
      "text": "object Main {\n    def main(args: Array[String]): Unit \u003d {\n        println(\"Some text\")\n    }\n}\nMain.main(\u0027asfd\u0027)",
      "user": "anonymous",
      "dateUpdated": "2022-02-07 12:51:57.750",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1644234360349_417299784",
      "id": "paragraph_1644234360349_417299784",
      "dateCreated": "2022-02-07 12:46:00.372",
      "dateStarted": "2022-02-07 12:51:57.766",
      "dateFinished": "2022-02-07 12:51:57.812",
      "status": "ERROR"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2022-02-07 13:54:09.197",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1644234368000_527136196",
      "id": "paragraph_1644234368000_527136196",
      "dateCreated": "2022-02-07 12:46:08.000",
      "status": "READY"
    }
  ],
  "name": "streaming_from_file",
  "id": "2GVAZPF2U",
  "defaultInterpreterGroup": "spark",
  "version": "0.10.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {}
}